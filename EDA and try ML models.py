# -*- coding: utf-8 -*-
"""9.airbnb-recruiting-new-user-bookings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mi-4OGZu4mCVDE7uGub_uZLA_sJWO5ht

# Exploratory Data Analysis for Airbnb New User Bookings datasets

## Importing relevant libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

pd.set_option("display.max.columns", None)
pd.set_option("display.precision", 2)

"""## loading datasets"""

age_gender_bkts = pd.read_csv('age_gender_bkts.csv')
countries = pd.read_csv('countries.csv')
#sessions = pd.read_csv('sessions.csv')
train_users = pd.read_csv('train_users_2.csv')
test_users = pd.read_csv('test_users.csv')

"""## Data Wrangling

### 1. Age-Gender Dataset
"""

age_gender_df = age_gender_bkts.copy()
age_gender_df.head()

age_gender_df['country_destination'].unique()

us_age_gender_df = age_gender_df[age_gender_df['country_destination'] == 'US']#.reset_index().drop('index', axis=1)
us_age_gender_df.head()

"""### 2. Countries Dataset"""

countries.head()

"""### 3. Sessions Dataset"""

#sessions.head()

"""### 4. Train Users Dataset"""

train_users_df = train_users.copy()

train_users_df.head()

train_users_df.shape

"""#### Exploring the dataset

#### Dataset Pandas Profiling
"""

!pip install ydata_profiling
from ydata_profiling import ProfileReport

profile = ProfileReport(train_users_df, title="Pandas Profiling Report")
profile.to_notebook_iframe()

"""#### Checking for missing values"""

train_users_df.isnull().sum()

"""#### Exploring variables"""

train_users_df.columns

"""**1. Date-time variables**"""

train_users_df.select_dtypes(exclude='object').columns

"""**date_account_created, date_first_booking and timestamp_first_active**

Convert `date_account_created`, `date_first_booking` and `timestamp_first_active` from `object` to `datetime` format
"""

train_users_df['date_account_created'] = pd.to_datetime(train_users_df['date_account_created'], format='%Y-%m-%d')
train_users_df['date_first_booking'] = pd.to_datetime(train_users_df['date_first_booking'], format='%Y-%m-%d')
train_users_df['timestamp_first_active'] = pd.to_datetime(train_users_df['timestamp_first_active'], format='%Y%m%d%H%M%S')

train_users_df.select_dtypes(exclude='object').columns

"""**Extract `day`, `month` from `date_first_booking`**"""

train_users_df['day_first_booking'] = train_users_df['date_first_booking'].dt.day_name()
train_users_df['day_first_booking'].unique()

day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
sns.countplot(x = train_users_df['day_first_booking'], order = day_order)

train_users_df['month_first_booking'] = train_users_df['date_first_booking'].dt.month_name()
train_users_df['month_first_booking'].unique()

month_order = ['January', 'February',  'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
sns.countplot(x = train_users_df['month_first_booking'], order = month_order)
plt.xticks(rotation=45);

"""**Extract `hour` from `timestamp_first_active` to check when airbnb member are active around day time**"""

train_users_df['hour_first_active'] = train_users_df['timestamp_first_active'].dt.hour
train_users_df['hour_first_active'].unique()

plt.figure(figsize=(12,4))
sns.countplot(x = train_users_df['hour_first_active'])

"""**2. Numerical variables**

**Age**
"""

train_users_df['age'].describe()

"""As we see from descriptive statistics of the **`age`**, the max value is **`2014`** which I think is wrong input (birth date instaed of age) so I will try to corret these values to avoid outliers."""

for i in range(train_users_df.shape[0]):
    if train_users_df.loc[i, 'age'] > 150:
        train_users_df.loc[i, 'age'] = train_users_df.loc[i, 'date_account_created'].year - train_users_df.loc[i, 'age']

train_users_df['age'][train_users_df['age'] > 150].unique()

sns.displot(train_users_df['age'], kde=True)

train_users_df['age'].describe()

train_users_df.loc[train_users_df['age'] >= 100, 'age'] = np.nan
train_users_df.loc[train_users_df['age'] <= 15, 'age'] = np.nan
sns.displot(train_users_df['age'], kde=True)

train_users_df['age'].describe()

train_users_df['age'].isnull().sum()

"""As we see, **`age`** column has **90804** missing values, about **42.5%** of the dataset but **`age`** is an important feature in prediction process so i will use **`miceforest`** to fill age column later.

**3. Categorical variables**
"""

cat_variables = train_users_df.select_dtypes(include='object').columns.values
cat_variables

"""**Gender**"""

sns.countplot(x=train_users_df['gender'])

train_users_df['gender'].value_counts()

train_users_df['gender'].replace({'-unknown-':np.nan, 'FEMALE':'female', 'MALE':'male', 'OTHER':np.nan}, inplace=True)

train_users_df['gender'].isnull().sum()

"""As we see, **`gender`** column has 95970 missing values, about **44.9%** of the dataset but **`gender`** is an important feature in prediction process so i will use **`miceforest`** to fill age column later."""

sns.countplot(x=train_users_df['gender'])

"""**Country destination**"""

sns.countplot(x=train_users_df['country_destination'])

train_users_df['country_destination'].value_counts()

train_users_df[train_users_df['date_first_booking'].isnull().any() and train_users_df['country_destination'] == 'NDF'].shape[0]

"""**As we see, Rows with missing `date_first_booking` are rows with `country_destination` is equal `NDF`, so I will drop these rows**"""

train_users_df.shape

train_users_df.dropna(subset='date_first_booking', axis=0, inplace=True)

train_users_df.shape

"""#### Data Imputation using `miceforest`"""

!pip install miceforest
import miceforest as mf

"""convert `object` columns to `category` type"""

train_users_df[train_users_df.select_dtypes(['object']).columns] = train_users_df.select_dtypes(['object']).apply(lambda x: x.astype('category'))

train_users_df.columns

target_col = ['gender', 'age', 'signup_method', 'signup_flow',
       'language', 'affiliate_channel', 'affiliate_provider',
       'first_affiliate_tracked', 'signup_app', 'first_device_type',
       'first_browser', 'country_destination']

remain_col = ['id', 'date_account_created', 'timestamp_first_active',
'date_first_booking']

rare_cat = ['id' ,'signup_flow', 'language',
            'affiliate_provider', 'first_affiliate_tracked', 'first_device_type',
            'first_browser', 'country_destination']

train_users_df.info()

data = train_users_df[target_col]

# Create kernel.
kernel = mf.ImputationKernel(
  data,
  save_all_iterations=True,
  random_state=1
)

# Printing the kernel will show you some high level information.
print(kernel)

# Run mice with our newly tuned parameters.
kernel.mice(2, n_estimators=50)

# Create completed dataset
completed_dataset = kernel.complete_data()

# Add imputed data to the original datasets
train_users_df[target_col] = completed_dataset

train_users_df.isnull().sum()

sns.displot(train_users_df['age'], kde=True)

"""I will use z-score method to nullify `age` outliers."""

from scipy import stats
train_users_df['z_scores'] = stats.zscore(train_users_df['age'])
train_users_df['abs_z_scores'] = train_users_df['z_scores'].abs()
threshold = 3
train_users_df.loc[train_users_df['abs_z_scores'] > threshold, 'age'] = np.nan
sns.displot(train_users_df['age'], kde=True)

train_users_df.dropna(subset='age', axis=0, inplace=True)

train_users_df.isnull().sum()

train_users_df['age'].describe()

"""#### Create cleaned train_users dataframe"""

train_users_df[train_users_df.select_dtypes(['category']).columns] = train_users_df.select_dtypes(['category']).apply(lambda x: x.astype('object'))

train_users_df.info()

train_users_df.columns

train_users_cleaned = train_users_df.drop(axis=1,
                                          columns=['day_first_booking', 'month_first_booking', 'hour_first_active','z_scores', 'abs_z_scores']).copy()
train_users_cleaned.head()

train_users_cleaned.shape

train_users_cleaned.to_csv('train_users_cleaned.csv')

"""### 5. Test Users Dataset"""

test_users_df = test_users.copy()

test_users_df.head()

test_users_df.shape

profile = ProfileReport(test_users_df, title="Pandas Profiling Report")
profile.to_notebook_iframe()

"""#### Check for duplicates"""

test_users_df.duplicated().sum()

test_users_df.isnull().sum()

"""#### Exploring variables"""

test_users_df.columns

"""#### date_account_created, date_first_booking and timestamp_first_active
Convert `date_account_created`, `date_first_booking` and `timestamp_first_active` from `object` to `datetime` format
"""

test_users_df['date_account_created'] = pd.to_datetime(test_users_df['date_account_created'], format='%Y-%m-%d')
test_users_df['date_first_booking'] = pd.to_datetime(test_users_df['date_first_booking'], format='%Y-%m-%d')
test_users_df['timestamp_first_active'] = pd.to_datetime(test_users_df['timestamp_first_active'], format='%Y%m%d%H%M%S')

"""**1. Numerical variables**

**Age**
"""

test_users_df['age'].describe()

for i in range(test_users_df.shape[0]):
    if test_users_df.loc[i, 'age'] > 150:
        test_users_df.loc[i, 'age'] = test_users_df.loc[i, 'date_account_created'].year - test_users_df.loc[i, 'age']

test_users_df['age'][test_users_df['age'] > 150].unique()

sns.displot(test_users_df['age'], kde=True)

test_users_df['age'].describe()

test_users_df.loc[test_users_df['age'] > 100, 'age'] = np.nan
test_users_df.loc[test_users_df['age'] < 18, 'age'] = np.nan
sns.displot(test_users_df['age'], kde=True)
plt.tight_layout()

test_users_df['age'].describe()

test_users_df['age'].isnull().sum()

"""As we see, **`age`** column has missing values, so i will use **`miceforest`** to fill age column later.

**3. Categorical variables**
"""

cat_variables = test_users_df.select_dtypes(include='object').columns.values
cat_variables

"""**Gender**"""

sns.countplot(x=test_users_df['gender'])

test_users_df['gender'].value_counts()

test_users_df['gender'].replace({'-unknown-':np.nan, 'FEMALE':'female', 'MALE':'male', 'OTHER':np.nan}, inplace=True)

test_users_df['gender'].isnull().sum()

"""As we see, **`gender`** column has 95970 missing values, about **44.9%** of the dataset but **`gender`** is an important feature in prediction process so i will use **`miceforest`** to fill age column later.

#### Data Imputation using `miceforest` algorithm

**convert `object` columns to `category` type**
"""

test_users_df[test_users_df.select_dtypes(['object']).columns] = test_users_df.select_dtypes(['object']).apply(lambda x: x.astype('category'))

test_users_df.columns

test_target_col = ['gender', 'age', 'signup_method', 'signup_flow',
       'language', 'affiliate_channel', 'affiliate_provider',
       'first_affiliate_tracked', 'signup_app', 'first_device_type',
       'first_browser']

test_remain_col = ['id', 'date_account_created', 'timestamp_first_active',
'date_first_booking']

test_rare_cat = ['id' ,'signup_flow', 'language', 'affiliate_provider', 'first_affiliate_tracked',
            'first_device_type', 'first_browser', 'country_destination']

test_data = test_users_df[test_target_col]

# Create kernel.
test_kernel = mf.ImputationKernel(
  test_data,
  save_all_iterations=True,
  random_state=1
)

# Printing the kernel will show you some high level information.
print(test_kernel)

# Run mice with our newly tuned parameters.
test_kernel.mice(2, n_estimators=50)

# Create completed dataset
completed_dataset = test_kernel.complete_data()

# Add imputed data to the original datasets
test_users_df[test_target_col] = completed_dataset

test_users_df.isnull().sum()

sns.displot(test_users_df['age'], kde=True)

from scipy import stats
test_users_df['z_scores'] = stats.zscore(test_users_df['age'])
test_users_df['abs_z_scores'] = test_users_df['z_scores'].abs()
threshold = 3
test_users_df.loc[test_users_df['abs_z_scores'] > threshold, 'age'] = np.nan
sns.displot(test_users_df['age'], kde=True)

test_users_df.dropna(subset='age', axis=0, inplace=True)

test_users_df.isnull().sum()

test_users_df['age'].describe()

"""#### Create cleaned train_users dataframe"""

test_users_df[test_users_df.select_dtypes(['category']).columns] = test_users_df.select_dtypes(['category']).apply(lambda x: x.astype('object'))

test_users_df.info()

test_users_df.columns

test_users_cleaned = test_users_df.drop(axis=1, columns=['z_scores', 'abs_z_scores']).copy()
test_users_cleaned.head()

test_users_cleaned.shape

test_users_cleaned.to_csv('test_users_cleaned.csv')

"""##############################################################################################################################

## ML modelling

### Train dataset
"""

train_users_cleaned.head()

X_train = train_users_cleaned.drop(['id', 'date_account_created', 'timestamp_first_active', 'date_first_booking'], axis=1).iloc[:, :-1]
y_train = train_users_cleaned.iloc[:, -1]

X_train.head()

y_train.head()

"""### Test dataset"""

test_users_cleaned.head()

X_test = test_users_cleaned.drop(['id', 'date_account_created', 'timestamp_first_active', 'date_first_booking'], axis=1)

X_test.head()

"""### Concatenating X_train and X_test to perform OneHotEncoding"""

train_shape = X_train.shape[0]
train_shape

X = pd.concat([X_train, X_test], ignore_index=True)
X.head()

"""### One Hot Encoding"""

cat_cols = X.select_dtypes(include='object').columns
cat_cols

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols)], remainder='passthrough')

X = ct.fit_transform(X)
X

pd.DataFrame(X.toarray()).head()

"""### Spliting X dataset to train set and test set"""

X_train = X[:train_shape, :]
X_test = X[train_shape:, :]

X_train.shape, X_test.shape

"""### Spliting train dataset to train set and validation set"""

from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)

"""### Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler(with_mean=False)
X_train[:, -2:] = sc.fit_transform(X_train[:, -2:])
X_val[:, -2:] = sc.fit_transform(X_val[:, -2:])
X_test[:, -2:] = sc.transform(X_test[:, -2:])

"""### Label Encoding"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y_train = le.fit_transform(y_train)

"""## 1. Decision Tree Classification"""

from sklearn.tree import DecisionTreeClassifier
dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)
dt_classifier.fit(X_train, y_train)

y_pred_dt = dt_classifier.predict(X_val)
y_pred_dt = le.inverse_transform(y_pred_dt)
y_pred_dt

from sklearn.metrics import accuracy_score

dt_accuracy_score = accuracy_score(y_val, y_pred_dt)
print('Accuracy Score = {:.2f}%'.format(dt_accuracy_score*100))

yhat_dt = dt_classifier.predict(X_test)
yhat_dt = le.inverse_transform(yhat_dt)
yhat_dt

"""## 2. Random Forest Classification"""

from sklearn.ensemble import RandomForestClassifier
rf_classifier = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)
rf_classifier.fit(X_train, y_train)

y_pred_rf = rf_classifier.predict(X_val)
y_pred_rf = le.inverse_transform(y_pred_rf)
y_pred_rf

from sklearn.metrics import accuracy_score

rf_accuracy_score = accuracy_score(y_val, y_pred_rf)
print('Accuracy Score = {:.2f}%'.format(rf_accuracy_score*100))

yhat_rf = rf_classifier.predict(X_test)
yhat_rf = le.inverse_transform(yhat_rf)
yhat_rf

"""## 3. KNN"""

from sklearn.neighbors import KNeighborsClassifier
knn_classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)
knn_classifier.fit(X_train, y_train)

y_pred_knn = knn_classifier.predict(X_val)
y_pred_knn = le.inverse_transform(y_pred_knn)
y_pred_knn

from sklearn.metrics import accuracy_score

knn_accuracy_score = accuracy_score(y_val, y_pred_knn)
print('Accuracy Score = {:.2f}%'.format(knn_accuracy_score*100))

yhat_knn = knn_classifier.predict(X_test)
yhat_knn = le.inverse_transform(yhat_knn)
yhat_knn

"""## 4. Naive Bayes"""

from sklearn.naive_bayes import MultinomialNB
nb_classifier = MultinomialNB()
nb_classifier.fit(X_train.toarray(), y_train)

y_pred_nb = nb_classifier.predict(X_val.toarray())
y_pred_nb = le.inverse_transform(y_pred_nb)
y_pred_nb

from sklearn.metrics import accuracy_score

nb_accuracy_score = accuracy_score(y_val, y_pred_nb)
print('Accuracy Score = {:.2f}%'.format(nb_accuracy_score*100))

yhat_nb = nb_classifier.predict(X_test.toarray())
yhat_nb = le.inverse_transform(yhat_nb)
yhat_nb

"""## 5. XGBoost model"""

from xgboost import XGBClassifier
xgb_classifier = XGBClassifier()
xgb_classifier.fit(X_train, y_train)

y_pred_xgb = xgb_classifier.predict(X_val)
y_pred_xgb = le.inverse_transform(y_pred_xgb)
y_pred_xgb

from sklearn.metrics import accuracy_score

xgb_accuracy_score = accuracy_score(y_val, y_pred_xgb)
print('Accuracy score = {:.2f} %'.format(xgb_accuracy_score*100))

yhat_xgb = xgb_classifier.predict(X_test)
yhat_xgb = le.inverse_transform(yhat_xgb)
yhat_xgb

"""## 6. CatBoost model"""

!pip install catboost

from catboost import CatBoostClassifier
cb_classifier = CatBoostClassifier()
cb_classifier.fit(X_train, y_train)

y_pred_cb = cb_classifier.predict(X_val).ravel()
y_pred_cb = le.inverse_transform(y_pred_cb)
y_pred_cb

from sklearn.metrics import accuracy_score

cb_accuracy_score = accuracy_score(y_val, y_pred_cb)
print('Accuracy score = {:.2f} %'.format(cb_accuracy_score*100))

yhat_cb = cb_classifier.predict(X_test).ravel()
yhat_cb = le.inverse_transform(yhat_cb)
yhat_cb

"""## Summary"""

model = ['Decision Tree', 'Random Forest', 'KNN', 'Naive Bayes', 'XGBoost', 'CatBoost']
accuracy = [dt_accuracy_score*100, rf_accuracy_score*100, knn_accuracy_score*100, nb_accuracy_score*100, xgb_accuracy_score*100, cb_accuracy_score*100]

summary = pd.DataFrame({'Model': model, 'Accuracy %': accuracy})
summary
